{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhpNbQnGb2kUZanW7DITQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerbeiPatricia/Retele-neuronale2024/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5CK9kGqqvCrG",
        "outputId": "547b80de-1421-4d5a-e170-8c1daa59eeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (60000, 784), Train labels shape: (60000, 10)\n",
            "Test data shape: (10000, 784), Test labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def download_mnist(is_train: bool):\n",
        "  dataset = MNIST(root='./data',\n",
        "                  transform=lambda x: np.array(x).flatten(),\n",
        "                  download=True,\n",
        "                  train=is_train)\n",
        "\n",
        "  mnist_data = []\n",
        "  mnist_labels = []\n",
        "  for image, label in dataset:\n",
        "\n",
        "    mnist_data.append(image / 255.0)\n",
        "    mnist_labels.append(label)\n",
        "\n",
        "\n",
        "  mnist_data = np.array(mnist_data)\n",
        "  mnist_labels = np.array(mnist_labels)\n",
        "\n",
        "\n",
        "  mnist_labels_one_hot = np.eye(10)[mnist_labels]\n",
        "\n",
        "  return mnist_data, mnist_labels_one_hot\n",
        "\n",
        "\n",
        "train_X, train_Y = download_mnist(True)\n",
        "test_X, test_Y = download_mnist(False)\n",
        "\n",
        "\n",
        "print(f'Train data shape: {train_X.shape}, Train labels shape: {train_Y.shape}')\n",
        "print(f'Test data shape: {test_X.shape}, Test labels shape: {test_Y.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import numpy as np\n",
        "\n",
        "def train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100):\n",
        "\n",
        "    W = np.random.randn(train_X.shape[1], 10) * 0.01\n",
        "    b = np.zeros((10,))\n",
        "\n",
        "    num_examples = train_X.shape[0]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        indices = np.arange(num_examples)\n",
        "        np.random.shuffle(indices)\n",
        "        train_X = train_X[indices]\n",
        "        train_Y = train_Y[indices]\n",
        "\n",
        "        for i in range(0, num_examples, batch_size):\n",
        "            X_batch = train_X[i:i + batch_size]\n",
        "            Y_batch = train_Y[i:i + batch_size]\n",
        "\n",
        "    return W, b\n",
        "\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.1\n",
        "W, b = train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100)\n"
      ],
      "metadata": {
        "id": "N5zuoZtjI7KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z )\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def forward_propagation(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    return y_pred\n",
        "\n",
        "def train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100):\n",
        "\n",
        "    W = np.random.randn(train_X.shape[1], 10) * 0.01\n",
        "    b = np.zeros((10,))\n",
        "\n",
        "    num_examples = train_X.shape[0]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        indices = np.arange(num_examples)\n",
        "        np.random.shuffle(indices)\n",
        "        train_X = train_X[indices]\n",
        "        train_Y = train_Y[indices]\n",
        "\n",
        "        for i in range(0, num_examples, batch_size):\n",
        "            X_batch = train_X[i:i + batch_size]\n",
        "            Y_batch = train_Y[i:i + batch_size]\n",
        "\n",
        "\n",
        "            y_pred_batch = forward_propagation(X_batch, W, b)\n",
        "\n",
        "    return W, b\n",
        "\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.1\n",
        "W, b = train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OPcV3Pt2JTjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z )\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    m = y_true.shape[0]\n",
        "    loss = -np.sum(y_true * np.log(y_pred+ 1e-9))\n",
        "    return loss\n",
        "\n",
        "def forward_propagation(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    return y_pred\n",
        "\n",
        "def backward_propagation(X, y_true, y_pred, W, b, learning_rate):\n",
        "    m = y_true.shape[0]\n",
        "    dz = y_true - y_pred\n",
        "\n",
        "\n",
        "    dW = np.dot(X.T, dz)\n",
        "    db = np.sum(dz, axis=0)\n",
        "\n",
        "\n",
        "    W += learning_rate * dW\n",
        "    b += learning_rate * db\n",
        "\n",
        "    return W, b\n",
        "\n",
        "def train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100):\n",
        "    W = np.random.randn(train_X.shape[1], 10) * 0.01\n",
        "    b = np.zeros((10,))\n",
        "\n",
        "    num_examples = train_X.shape[0]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        indices = np.arange(num_examples)\n",
        "        np.random.shuffle(indices)\n",
        "        train_X = train_X[indices]\n",
        "        train_Y = train_Y[indices]\n",
        "\n",
        "\n",
        "        for i in range(0, num_examples, batch_size):\n",
        "            X_batch = train_X[i:i + batch_size]\n",
        "            Y_batch = train_Y[i:i + batch_size]\n",
        "\n",
        "\n",
        "            y_pred_batch = forward_propagation(X_batch, W, b)\n",
        "\n",
        "            loss = cross_entropy_loss(y_pred_batch, Y_batch)\n",
        "\n",
        "\n",
        "            W, b = backward_propagation(X_batch, Y_batch, y_pred_batch, W, b, learning_rate)\n",
        "\n",
        "\n",
        "    return W, b\n",
        "\n",
        "def test_predict(X, W, b):\n",
        "    y_pred = forward_propagation(X, W, b)\n",
        "    return np.argmax(y_pred, axis=1)\n",
        "\n",
        "num_epochs = 50\n",
        "learning_rate = 0.2\n",
        "W, b = train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100)\n",
        "\n",
        "y_test_pred = test_predict(test_X, W, b)\n",
        "test_accuracy = np.mean(np.argmax(test_Y, axis=1) == y_test_pred)\n",
        "print(f'Acuratețea pe setul de testare: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uLuJSnLG2NEu",
        "outputId": "3f73db5d-fea4-4112-a130-1efcda641634"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuratețea pe setul de testare: 0.9071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z)\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    m = y_true.shape[0]\n",
        "    loss = -np.sum(y_true * np.log(y_pred+1e-9))\n",
        "    return loss\n",
        "\n",
        "def forward_propagation(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    return y_pred\n",
        "\n",
        "def gradient_descent(X, y_true, y_pred, W, b, learning_rate):\n",
        "    m = y_true.shape[0]\n",
        "    dz = y_true - y_pred\n",
        "\n",
        "    dW = np.dot(X.T, dz)\n",
        "    db = np.sum(dz, axis=0)\n",
        "\n",
        "    W += learning_rate * dW\n",
        "    b += learning_rate * db\n",
        "\n",
        "    return W, b\n",
        "\n",
        "def train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100):\n",
        "    W = np.random.randn(train_X.shape[1], 10) * 0.01\n",
        "    b = np.zeros((10,))\n",
        "\n",
        "    num_examples = train_X.shape[0]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        indices = np.arange(num_examples)\n",
        "        np.random.shuffle(indices)\n",
        "        train_X = train_X[indices]\n",
        "        train_Y = train_Y[indices]\n",
        "\n",
        "        for i in range(0, num_examples, batch_size):\n",
        "            X_batch = train_X[i:i + batch_size]\n",
        "            Y_batch = train_Y[i:i + batch_size]\n",
        "\n",
        "            y_pred_batch = forward_propagation(X_batch, W, b)\n",
        "\n",
        "            W, b = gradient_descent(X_batch, Y_batch, y_pred_batch, W, b, learning_rate)\n",
        "\n",
        "    return W, b\n",
        "\n",
        "def download_mnist(is_train: bool):\n",
        "    dataset = MNIST(root='./data', transform=lambda x: np.array(x).flatten(), download=True, train=is_train)\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "    for image, label in dataset:\n",
        "        mnist_data.append(image / 255.0)\n",
        "        mnist_labels.append(label)\n",
        "    mnist_data = np.array(mnist_data)\n",
        "    mnist_labels = np.array(mnist_labels)\n",
        "    mnist_labels_one_hot = np.eye(10)[mnist_labels]\n",
        "    return mnist_data, mnist_labels_one_hot\n",
        "\n",
        "train_X, train_Y = download_mnist(True)\n",
        "test_X, test_Y = download_mnist(False)\n",
        "\n",
        "num_epochs = 1\n",
        "learning_rate = 0.2\n",
        "W, b = train_neural_network(train_X, train_Y, num_epochs, learning_rate, batch_size=100)\n",
        "\n",
        "def test_predict(X, W, b):\n",
        "    y_pred = forward_propagation(X, W, b)\n",
        "    return np.argmax(y_pred, axis=1)\n",
        "\n",
        "y_test_pred = test_predict(test_X, W, b)\n",
        "test_accuracy = np.mean(np.argmax(test_Y, axis=1) == y_test_pred)\n",
        "print(f'Acuratețea pe setul de testare: {test_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wCL0PsW2vypa",
        "outputId": "14fc864e-7f7f-42db-e8cc-26c7880a15a8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuratețea pe setul de testare: 0.8437\n"
          ]
        }
      ]
    }
  ]
}